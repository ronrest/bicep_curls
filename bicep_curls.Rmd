---
title: "Bicep Curls"
author: "Ronny Restrepo"
date: "21/05/2015"
output: html_document
---


```{r setup, cache = FALSE, echo = FALSE, message = FALSE, warning = FALSE, tidy = FALSE}
# make this an external chunk that can be included in any file
library(knitr)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, 
               fig.align = 'center', dpi = 100, tidy = F, 
               cache.path = '.cache/', cache=TRUE, 
               fig.path = 'fig/', fig.height=3, fig.width=4)

options(xtable.type = 'html')

knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```



# TIPS
- `readRDS()` and `saveRDS()` for caching R objects such as the trained data. 
-  use variable Importance `varImp()` function on the trained model. It shows the most important variables. 
- Use `myModel$results` for a summary of accuracy results

```{r conveniencelibs}
#Uncomment the following lines if you want to install 
#   file.convenience package
#   stat.convenience package
#   fancyprint       package
#library(devtools)
#TODO: XXXX install from github code

#library(file.convenience)
#library(stat.convenience)

```

```{r getData, dependson=conveniencelibs}
#===============================================================================
#                                                        DOWNLOAD AND CACHE DATA
#===============================================================================
trainURL = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
predictURL = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

library(file.convenience)        # Not in CRAN, see Appendix to get this package
cacheDownload(trainURL, dataDir="data", localName="trainData")
cacheDownload(predictURL, dataDir="data", localName="predictionData")
```


``` {r loadData, dependson="getData"}
#===============================================================================
#                                                                      LOAD DATA
#===============================================================================
na.strings = c("NA", "#DIV/0!")
rawData = read.csv("data/trainData", na.strings=na.strings, stringsAsFactors=FALSE)
predictData = read.csv("data/predictionData", na.strings=na.strings, 
                   stringsAsFactors=FALSE)
```

```{r summary, dependson="loadData"}
#===============================================================================
#                                                                       SUMMARY
#===============================================================================
# TODO: remove the detach line
#detach("package:stat.convenience", unload=TRUE)
library(fancyprint)              # Not in CRAN, see Appendix to get this package
library(stat.convenience)        # Not in CRAN, see Appendix to get this package
na.info = na.summary(rawData, only.nas=TRUE)
nrow(na.info)

#na.summary(test, only.nas=TRUE)
```

We can see from the the summary of NAs, that there are 100 columns with NAs. Out 
of those columns, the proportion of NAs range from  
`r round(min(na.info$proportion) * 100, digits=2)`% to 
`r round(max(na.info$proportion) * 100, digits=2)`% of the rows. This means it 
is not really worth keeping those columns in the dataset, so we keep a subset of 
the columns that dont have any NAs. 

There are some aditional columns that are not much use to us as predictor 
variables, so they are filtered also. 

```{r filterColumns, dependson="loadData"}
#===============================================================================
#                                                                 FILTER COLUMNS
#===============================================================================
# Create filter of columns with the NAs
column_filter <- na.info$colName

# Filter includes aditional columns that are not useful for prediction
column_filter <- c(column_filter, "X", "user_name", "raw_timestamp_part_1", 
                   "raw_timestamp_part_2", "cvtd_timestamp", "new_window", 
                   "num_window")

# Actually filter out the columns using the filter
# filter.columns() is in the stat.convenience package
cleanData <- filter.columns(rawData, column_filter, method="list", exclude=TRUE)
predictData <- filter.columns(predictData, column_filter, method="list", exclude=TRUE)

# Convert the class column to factor type
cleanData$classe <- as.factor(cleanData$classe)
```

What we end up with is `r ncol(cleanData)` columns. `r ncol(cleanData) - 1` of 
them to be used as predictor variables, and the column labelled `classe` 
provides the labels to be used in training the learning algorithm. 

Now that the data has been cleaned up a bit, we can split the data into a 
training and test set. 60% of the data is assigned to the training set, and 40% 
to the test set. 



```{r splitData}
#===============================================================================
#                                                                     SPLIT DATA
#===============================================================================
library(caret)
set.seed(974)
inTrain <- createDataPartition(y=cleanData$classe, p=0.6, list=FALSE)
trainData <- cleanData[inTrain,]
testData <- cleanData[-inTrain,]
```

Now we can train the learning algorithm. 

```{r}
#===============================================================================
#                                                                     TRAIN DATA
#===============================================================================
#Uncomment to set number of cores in Revolution R
#library(RevoUtilsMath)
#setMKLthreads(2)

#install.packages("doParallel")
library(doParallel)




################################################################################
#                                                                      FINALISTS
################################################################################
#=========================================================================
#                                    gbm, center&scale, repeatedcv n10, r3
#                                                   TRYING NOW ON TESTDATA                                                                      
library("gbm")
registerDoParallel(cores=2)
# cores=8     miniTrain  elapsed=   29.840
# cores=2     miniTrain2 elapsed=   59.200
# cores=2     trainData  elapsed=   782.468

system.time({
    tc <- trainControl(method="repeatedcv", number=10, repeats=3)
    modFit3 <- train(classe ~ ., method="gbm", verbose=FALSE,
                    preProcess=c("center","scale"), trControl=tc, 
                    data=trainData)
})
print(modFit3)
# miniTrain    preprocess= center,scale  Accuracy   0.7240634 - 0.9009502
# miniTrain2   preprocess= center,scale  Accuracy   0.7498513 - 0.9289771
# trainData    preprocess= center,scale  Accuracy   0.7544986 - 0.9606821
#saveRDS(modFit3, "modFit_gbm_center_scale_repeatedCV_n1-_r3_trainData.rds")
#=========================================================================

#=========================================================================
#                        Random Forrest, no preprocess, repeatedcv n10, r3 
#                                                              PRETTY GOOD
registerDoParallel(cores=2)
# cores=8     miniTrain  elapsed=   72.190
# cores=8     miniTrain2 elapsed=  194.933
# cores=8     miniTrain4 elapsed=  269.738      with n=5
# cores=8     miniTrain4 elapsed=  652.625      with n=10
# cores=2     trainData  elapsed=  6756.159     


system.time({
    tc <- trainControl(method="repeatedcv", number=10, repeats=3)
    modFit3 <- train(classe ~ ., method="rf", prox=TRUE,  trControl=tc, 
                     data=trainData)
})
print(modFit3)
# miniTrain    preprocess= NA  Accuracy   0.9053133  - 0.9078660
# miniTrain2   preprocess= NA  Accuracy   0.9468010  - 0.9469440
# miniTrain4   preprocess= NA  Accuracy   0.9643448  - 0.9695097  with n=5
# miniTrain4   preprocess= NA  Accuracy   0.9687342  - 0.9743236  with n=10
# trainData    preprocess= NA  Accuracy   0.9856776  - 0.9907160  kappa=0.9882559

#saveRDS(modFit3, "modFit_rf_noPreproc_repeatedCv_n10_r3_trainData.rds")
#=========================================================================

#=========================================================================
#                      Random Forrest, center&scale, repeatedcv n10, r3
registerDoParallel(cores=2)
# cores=8     miniTrain  elapsed=   77.471
# cores=8     miniTrain2 elapsed=  203.801
# cores=2     trainData  elapsed=  5855.466
# 
set.seed(473)
system.time({
    tc <- trainControl(method="repeatedcv", number=10, repeats=3)
    modFit3 <- train(classe ~ ., method="rf", prox=TRUE, 
                     preProcess=c("center","scale"), trControl=tc, 
                     data=trainData)
})
print(modFit3)
# miniTrain    preprocess= center,scale  Accuracy   0.8996508  - 0.9089277
# miniTrain2   preprocess= center,scale  Accuracy   0.9470743  - 0.9548542
# trainData   preprocess= center,scale  Accuracy   0.9844323  - 0.9905175

#saveRDS(modFit3, "modFit_rf_centreScale_repeatedcv_n10_r3_trainData.rds")
#=========================================================================







#myfile = cacheprocess("filename", funct, ...)






#-------------------------------------------------------------------------------
#                                                RANDOM FORREST NO PREPROCESSING
#-------------------------------------------------------------------------------
# Accuracy    0.9907160
# Kappa       0.9882559
rf_rcv_nopp = readRDS("trained_objects/modFit_rf_noPreproc_repeatedCv_n10_r3_trainData.rds")

rf_rcv_nopp$finalModel


#-------------------------------------------------------------------------------
#                                                    RANDOM FORREST CENTER SCALE
#-------------------------------------------------------------------------------
# Accuracy   0.9905175
# Kappa      0.9880041
rf_rcv_normalize = readRDS("trained_objects/modFit_rf_centreScale_repeatedcv_n10_r3_trainData.rds")

rf_rcv_normalize$finalModel
getTree(rf_rcv_normalize$finalModel)



#-------------------------------------------------------------------------------
#                                                                       BOOSTING
#-------------------------------------------------------------------------------
gbm_rcv_normalize = readRDS("trained_objects/modFit_gbm_center_scale_repeatedCV_n1-_r3_trainData.rds")




# relative importance of different variables
varImp(rf_rcv_nopp)
varImp(rf_rcv_normalize)
```

We can see that the three most important variables in predicting the categories 
are roll_belt, pitch_forearm and yaw_belt.




```{r test}
#===============================================================================
#                                                               TEST ON TESTDATA
#===============================================================================

#-------------------------------------------------------------------------------
#                                                RANDOM FORREST NO PREPROCESSING
#-------------------------------------------------------------------------------
# Accuracy :   0.9908          
# 95% CI :    (0.9885, 0.9928)
# Kappa :      0.9884
# Sensitivity            0.9982   0.9875   0.9876   0.9876   0.9889
# Specificity            0.9971   0.9973   0.9961   0.9980   0.9998
# Balanced Accuracy      0.9977   0.9924   0.9919   0.9928   0.9944

pred <- predict(rf_rcv_nopp, testData) 
table(pred,testData$classe)
confusionMatrix(pred, testData$classe)

#-------------------------------------------------------------------------------
#                                                    RANDOM FORREST CENTER SCALE
#-------------------------------------------------------------------------------
# Accuracy :   0.9901          
# 95% CI :    (0.9876, 0.9921)
# Kappa :      0.9874 
# Sensitivity            0.9973   0.9862   0.9861   0.9876   0.9889
# Specificity            0.9968   0.9967   0.9960   0.9982   0.9998
# Balanced Accuracy      0.9971   0.9914   0.9910   0.9929   0.9944

pred <- predict(rf_rcv_normalize, testData) 
table(pred,testData$classe)
confusionMatrix(pred, testData$classe)
```



``` {r predict}
newPred <- predict(rf_rcv_nopp, predictData) 
```

``` {r exploratoryPlots, dependson="filterColumns"}
#===============================================================================
#                                                              EXPLORATORY PLOTS
#===============================================================================
# library(ggplot2)
# qplot(pitch_forearm, roll_forearm, color=classe, data=cleanData)
# qplot(yaw_belt, roll_belt, color=classe, data=cleanData)
# qplot(yaw_belt, magnet_dumbbell_z, color=classe, data=cleanData)
# qplot(yaw_belt, magnet_dumbbell_y, color=classe, data=cleanData)  
# qplot(magnet_dumbbell_z, magnet_dumbbell_y, color=classe, data=cleanData)
# qplot(roll_belt, magnet_dumbbell_z, color=classe, data=cleanData)
# qplot(roll_belt, magnet_dumbbell_y, color=classe, data=cleanData)  
```



```{r}
#===============================================================================
#                                                                 EXPORT ANSWERS
#===============================================================================
#answers = rep("A", 20)
#answers = c("A", "B", "A", "C", "A", "B", "A", "C", "A")

#then you can load this function by copying and pasting it into R: 
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("answers/","problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
#then create a folder where you want the files to be written. 
# Set that to be your working directory and run:
 
pml_write_files(newPred)
```


"R version 3.2.0 (2015-04-16)"
